<!-- Elements added to main will be displayed on all pages -->

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift.">
      
      
      
        <link rel="canonical" href="https://ai-on-openshift.io/demos/llm-chat-doc/llm-chat-doc/">
      
      
        <link rel="prev" href="../../financial-fraud-detection/financial-fraud-detection/">
      
      
        <link rel="next" href="../../retail-object-detection/retail-object-detection/">
      
      
      <link rel="icon" href="../../../assets/robot-head.ico">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.7">
    
    
      
        <title>LLMs, Chatbots, Talk with your Doc,... - AI on OpenShift</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.4b4a2bd9.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-EXFP0W7LTY"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-EXFP0W7LTY",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-EXFP0W7LTY",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="LLMs, Chatbots, Talk with your Doc,... - AI on OpenShift" >
      
        <meta  property="og:description"  content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift." >
      
        <meta  property="og:image"  content="https://ai-on-openshift.io/assets/images/social/demos/llm-chat-doc/llm-chat-doc.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://ai-on-openshift.io/demos/llm-chat-doc/llm-chat-doc/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="LLMs, Chatbots, Talk with your Doc,... - AI on OpenShift" >
      
        <meta  name="twitter:description"  content="The one-stop shop for Data Science and Data Engineering on OpenShift! Tools and applications, patterns, demos, tips and tricks, everything needed by Data Science and Data Engineering practitioners on OpenShift." >
      
        <meta  name="twitter:image"  content="https://ai-on-openshift.io/assets/images/social/demos/llm-chat-doc/llm-chat-doc.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="red">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llms-chatbots-talk-with-your-documentation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="AI on OpenShift" class="md-header__button md-logo" aria-label="AI on OpenShift" data-md-component="logo">
      
  <img src="../../../assets/robot-head.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI on OpenShift
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LLMs, Chatbots, Talk with your Doc,...
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="red"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/opendatahub-io-contrib/ai-on-openshift" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../whats-new/whats-new/" class="md-tabs__link">
        
  
    
  
  What's new?

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../getting-started/why-this-site/" class="md-tabs__link">
          
  
    
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../odh-rhods/configuration/" class="md-tabs__link">
          
  
    
  
  ODH/RHODS How-Tos

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../tools-and-applications/airflow/airflow/" class="md-tabs__link">
          
  
    
  
  Tools and Applications

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../patterns/bucket-notifications/bucket-notifications/" class="md-tabs__link">
          
  
    
  
  Patterns

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../credit-card-fraud-detection-mlflow/credit-card-fraud/" class="md-tabs__link">
          
  
    
  
  Demos

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AI on OpenShift" class="md-nav__button md-logo" aria-label="AI on OpenShift" data-md-component="logo">
      
  <img src="../../../assets/robot-head.svg" alt="logo">

    </a>
    AI on OpenShift
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/opendatahub-io-contrib/ai-on-openshift" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../whats-new/whats-new/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What's new?
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/why-this-site/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Why this site?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/openshift/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift and AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/opendatahub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open Data Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/openshift-data-science/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift Data Science
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    ODH/RHODS How-Tos
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            ODH/RHODS How-Tos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../odh-rhods/configuration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dashboard configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../odh-rhods/custom-notebooks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom notebooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../odh-rhods/nvidia-gpus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NVIDIA GPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../odh-rhods/custom-runtime-triton/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Serving Runtime (Triton)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../odh-rhods/openshift-group-management/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenShift Group Management
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tools and Applications
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Tools and Applications
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/airflow/airflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Airflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/apache-spark/apache-spark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Spark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/apache-nifi/apache-nifi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache NiFi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/mlflow/mlflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MLflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/riva/riva/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NVIDIA Riva
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/rclone/rclone/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Rclone
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../tools-and-applications/minio/minio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Minio
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Patterns
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Patterns
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../patterns/bucket-notifications/bucket-notifications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bucket notifications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../patterns/kafka/kafka-to-object-storage/kafka-to-object-storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kafka to object storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../patterns/kafka/kafka-to-serverless/kafka-to-serverless/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kafka to serverless
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../patterns/starproxy/starproxy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Starburst/Trino proxy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Demos
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Demos
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../credit-card-fraud-detection-mlflow/credit-card-fraud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Credit Card Fraud Detection with MLFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../financial-fraud-detection/financial-fraud-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Financial Fraud Detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    LLMs, Chatbots, Talk with your Doc,...
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    LLMs, Chatbots, Talk with your Doc,...
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#context-and-definitions" class="md-nav__link">
    Context and definitions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-serving" class="md-nav__link">
    LLM Serving
  </a>
  
    <nav class="md-nav" aria-label="LLM Serving">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-serving-solutions" class="md-nav__link">
    LLM Serving solutions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-model-to-use" class="md-nav__link">
    Which model to use?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-consumption" class="md-nav__link">
    LLM Consumption
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rag-chatbot-full-walkthrough" class="md-nav__link">
    RAG Chatbot Full Walkthrough
  </a>
  
    <nav class="md-nav" aria-label="RAG Chatbot Full Walkthrough">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    Requirements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-serving" class="md-nav__link">
    Model Serving
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-store" class="md-nav__link">
    Vector Store
  </a>
  
    <nav class="md-nav" aria-label="Vector Store">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#redis-deployment" class="md-nav__link">
    Redis deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#document-ingestion" class="md-nav__link">
    Document ingestion
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing" class="md-nav__link">
    Testing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#application" class="md-nav__link">
    Application
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../retail-object-detection/retail-object-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Object Detection in Retail
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../robotics-edge/robotics-edge/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Robotics at the Edge
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../smart-city/smart-city/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Smart City
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../telecom-customer-churn-airflow/telecom-customer-churn-airflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Telecom Customer Churn with Airflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../water-pump-failure-prediction/water-pump-failure-prediction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Water Pump Failure Prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../xray-pipeline/xray-pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XRay Pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../yolov5-training-serving/yolov5-training-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    YOLOv5 Training and Serving
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#context-and-definitions" class="md-nav__link">
    Context and definitions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-serving" class="md-nav__link">
    LLM Serving
  </a>
  
    <nav class="md-nav" aria-label="LLM Serving">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#llm-serving-solutions" class="md-nav__link">
    LLM Serving solutions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#which-model-to-use" class="md-nav__link">
    Which model to use?
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llm-consumption" class="md-nav__link">
    LLM Consumption
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rag-chatbot-full-walkthrough" class="md-nav__link">
    RAG Chatbot Full Walkthrough
  </a>
  
    <nav class="md-nav" aria-label="RAG Chatbot Full Walkthrough">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    Requirements
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-serving" class="md-nav__link">
    Model Serving
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-store" class="md-nav__link">
    Vector Store
  </a>
  
    <nav class="md-nav" aria-label="Vector Store">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#redis-deployment" class="md-nav__link">
    Redis deployment
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#document-ingestion" class="md-nav__link">
    Document ingestion
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#testing" class="md-nav__link">
    Testing
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#application" class="md-nav__link">
    Application
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="llms-chatbots-talk-with-your-documentation">LLMs, Chatbots, Talk with your Documentation</h1>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>All source files and examples used in this article are available on <strong><a href="https://github.com/rh-aiservices-bu/llm-on-openshift" target="_blank">this repo</a></strong>!</p>
</div>
<p><strong>LLMs (Large Language Models)</strong> are the subject of the day. And of course, you can definitely work with them on OpenShift with ODH or RHODS, from creating a simple Chatbot, or using them as simple APIs to summarize or translate texts, to deploying a full application that will allow you to quickly query your documentation or knowledge base in natural language.</p>
<p>You will find on this page instructions and examples on how to set up the different elements that are needed for those different use cases, as well as fully implemented and ready-to-use applications.</p>
<h2 id="context-and-definitions">Context and definitions</h2>
<p>Many people are only beginning to discover those technologies. After all, it has been less than a year since the general public is aware of them, and many related technologies, tools or applications are only a few months, even weeks (and sometimes days!) old. So here are a few definitions of the different terms that will be used in this article.</p>
<ul>
<li><strong>LLM</strong>: A Large Language Model (LLM) is a sophisticated artificial intelligence system designed for natural language processing. It leverages deep learning techniques to understand and generate human-like text. LLMs use vast datasets to learn language patterns, enabling tasks like text generation, translation, summarization, and more. These models are versatile and can be fine-tuned for specific applications, like chatbots or content creation. LLMs have wide-ranging potential in various industries, from customer support and content generation to research and education, but their use also raises concerns about ethics, bias, and data privacy, necessitating responsible deployment and ongoing research.</li>
<li><strong>Fine-tuning</strong>: Fine-tuning in the context of Large Language Models (LLMs) is a process of adapting a pre-trained, general-purpose model to perform specific tasks or cater to particular applications. It involves training the model on a narrower dataset related to the desired task, allowing it to specialize and improve performance. Fine-tuning customizes the LLM's capabilities for tasks like sentiment analysis, question answering, or chatbots. This process involves adjusting hyperparameters, data preprocessing, and possibly modifying the model architecture. Fine-tuning enables LLMs to be more effective and efficient in specific domains, extending their utility across various applications while preserving their initial language understanding capabilities.</li>
<li><strong>RAG</strong>: RAG, or Retrieval-Augmented Generation, is a framework in natural language processing. It combines two key components: retrieval and generation. Retrieval involves selecting relevant information from a vast knowledge base, like the internet, and generation pertains to creating human-like text. RAG models employ a retriever to fetch context and facts related to a specific query or topic and a generator, often a language model, to produce coherent responses. This approach enhances the quality and relevance of generated text, making it useful for tasks like question answering, content summarization, and information synthesis, offering a versatile solution for leveraging external knowledge in AI-powered language understanding and production.</li>
<li><strong>Embeddings</strong>: Embeddings refer to a technique in natural language processing and machine learning where words, phrases, or entities are represented as multi-dimensional vectors in a continuous vector space. These vectors capture semantic relationships and similarities between words based on their context and usage. Embeddings are created through unsupervised learning, often using models like Word2Vec or GloVe, which transform words into fixed-length numerical representations. These representations enable machines to better understand and process language, as similar words have closer vector representations, allowing algorithms to learn contextual associations. Embeddings are foundational in tasks like text classification, sentiment analysis, machine translation, and recommendation systems.</li>
<li><strong>Vector Database</strong>: A vector database is a type of database designed to efficiently store and manage vector data, which represents information as multidimensional arrays or vectors. Unlike traditional relational databases, which organize data in structured tables, vector databases excel at handling unstructured or semi-structured data. They are well-suited for applications in data science, machine learning, and spatial data analysis, as they enable efficient storage, retrieval, and manipulation of high-dimensional data points. Vector databases play a crucial role in various fields, such as recommendation systems, image processing, natural language processing, and geospatial analysis, by facilitating complex mathematical operations on vector data for insights and decision-making.</li>
<li><strong>Quantization</strong>: Model quantization is a technique in machine learning and deep learning aimed at reducing the computational and memory requirements of neural networks. It involves converting high-precision model parameters (usually 32-bit floating-point values) into lower precision formats (typically 8-bit integers or even binary values). This process helps in compressing the model, making it more lightweight and faster to execute on hardware with limited resources, such as edge devices or mobile phones. Quantization can result in some loss of model accuracy, but it's a trade-off that balances efficiency with performance, enabling the deployment of deep learning models in resource-constrained environments without significant sacrifices in functionality.</li>
</ul>
<p><em>Fun fact: all those definitions were generated by an LLM...</em></p>
<div class="admonition note">
<p class="admonition-title">Do you want to know more?</p>
<p>Here are a few worth reading articles:</p>
<ul>
<li><a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank">Best article ever: A jargon-free explanation of how AI large language models work</a></li>
<li><a href="https://medium.com/towards-generative-ai/understanding-llama-2-architecture-its-ginormous-impact-on-genai-e278cb81bd5c" target="_blank">Understanding LLama2 and its architecture</a></li>
<li><a href="https://medium.com/towards-data-science/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7" target="_blank">RAG vs Fine-Tuning, which is best?</a></li>
</ul>
</div>
<h2 id="llm-serving">LLM Serving</h2>
<p>LLM Serving is not a trivial task, at least in a production environment...</p>
<p><img alt="One does not simply serve an LLM" src="../img/one-does-not.png" width="500" /></p>
<ul>
<li>LLMs are usually huge (several GBs, tens of GBs...) and require GPU(s) with enough memory if you want decent accuracy and performance. Granted, you can run smaller models on home hardware with good results, but that's not the subject here. After all we are on OpenShift, so more in a large organization environment than in an enthusiastic programmer basement!</li>
<li>A served LLM will generally be used by multiple applications and users simultaneously. Since you can't just throw resources at it and scale your infrastructure easily because of the previous point, you want to optimize response time by for example batching queries, caching or buffering them,... Those are special operations that have to be handled specifically.</li>
<li>When you load an LLM, there are parameters you want to tweak at load time, so a "generic" loader is not the best suited solution.</li>
</ul>
<h3 id="llm-serving-solutions">LLM Serving solutions</h3>
<p>Fortunately, we have different solutions to handle LLM Serving:</p>
<ul>
<li><strong><a href="https://github.com/opendatahub-io/caikit-tgis-serving" target="_blank">Caikit-TGIS-Serving</a></strong> is a solution already available in ODH, soon to be included in RHODS, specially designed to serve LLMs. You will find all <a href="https://github.com/opendatahub-io/caikit-tgis-serving#installation" target="_blank">installation instructions</a> on its repo.</li>
<li><strong><a href="https://github.com/huggingface/text-generation-inference" target="_blank">Hugging Face Text Generation Inference</a></strong> is another solution that you can deploy on OpenShift following those <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/tree/main/hf_tgis_deployment">installation instructions</a>.</li>
</ul>
<p>What are the differences between the two?</p>
<ul>
<li>At the moment, the Caikit+TGIS stack installation may be a little bit more complicated, requiring different operators, configuration, certificate generation...</li>
<li>Also, at the moment, Caikit+TGIS has a gRPC interface only, which makes it more complicated to use, especially with other tools and SDKs that may not have integration with it.</li>
<li>HF TGI, while easier and providing a REST interface, comes with a caveat: its special license does not allow you to use it for a business that would provide on-demand LLM endpoints. You can totally use it for your own chatbots, even commercially (meaning the chatbots will be used by customers). But you cannot use it to make a business of simply hosting and serving LLMs.</li>
</ul>
<h3 id="which-model-to-use">Which model to use?</h3>
<p>In this section we will assume that you want to work with a "local" open source model, and not consume a commercial one through an API, like OpenAI's ChatGPT or Anthropic's Claude.</p>
<p>There are literally hundreds of thousands of models available, almost all of them available on the <a href="https://huggingface.co/">Hugging Face</a> site. If you don't know what this site is, you can think of it as what Quay or DockerHub are for containers: a big repository of models and datasets ready to download and use. Of course Hugging Face (the company) is also creating code, providing hosting capabilities,... but that's another story.</p>
<p>So which model to choose will depend on several factors:</p>
<ul>
<li>Of course how good this model is. There are several benchmarks that have been published, as well as constantly updated rankings.</li>
<li>The dataset it was trained on. Was it curated or just raw data from anywhere, does it contain nsfw material,...? And of course what the license is (some datasets are provided for research only or non-commercial).</li>
<li>The license of the model itself. Some are fully open source, some claim to be... They may be free to use in most cases, but have some restrictions attached to them (looking at you Llama2...).</li>
<li>The size of the model. Unfortunately that may be the most restrictive point for your choice. The model simply must fit on the hardware you have at your disposal, or the amount of money you are willing to pay.</li>
</ul>
<p>Currently, a good model with interesting performance for a relatively small size is <strong><a href="https://huggingface.co/mistralai/Mistral-7B-v0.1" target="_blank">Mistral-7B</a></strong>. Fully Open Source with an Apache 2.0 license, it will fit in an unquantized version on about 22GB of VRAM, which is perfect for an A10G card.</p>
<h2 id="llm-consumption">LLM Consumption</h2>
<p>Once served, consuming an LLM is pretty straightforward, as at the end of the day it's <em>only</em> an API call.</p>
<ul>
<li>For Caikit+TGIS you will <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/examples/notebooks/caikit-basic-query/caikit_grpc_query_example.ipynb" target="_blank">find here</a> a notebook example on how to connect and use the gRPC interface.</li>
<li>As HF TGI provides a REST interface, its usage is more straightforward. Here is the <a href="https://huggingface.github.io/text-generation-inference/" target="_blank">full API Swagger doc</a> (also available when you deploy the server yourself).</li>
</ul>
<p>However, for easier consumption and integration with other tools, a few libraries/SDKs are available to streamline the process. They will allow you to easily connect to Vector Databases or Search Agents, chain multiple models, tweak parameters,... in a few lines of code. The two main libraries at the time of this writing are <a href="https://www.langchain.com/" target="_blank">Langchain</a> and <a href="https://haystack.deepset.ai/" target="_blank">Haystack</a>.</p>
<p>In the <strong><a href="https://github.com/rh-aiservices-bu/llm-on-openshift" target="_blank">LLM on OpenShift</a></strong> repo, you will find several notebooks and full UI examples that will show you how to use those libraries with both Caikit+TGIS and HF-TGI to create your own <strong>Chatbot</strong>!</p>
<h2 id="rag-chatbot-full-walkthrough">RAG Chatbot Full Walkthrough</h2>
<p>Although the available code is normally pretty well documented, especially the notebooks, giving a full overview will surely help you understand how all of the different elements fit together.</p>
<p>For this walkthrough we will be using <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/tree/main/examples/ui/gradio/gradio-hftgi-rag-redis" target="_blank">this application</a>, which is a RAG-based Chatbot that will use a <a href="https://redis.io/" target="_blank">Redis</a> database as the vector store, <a href="https://github.com/huggingface/text-generation-inference" target="_blank">Hugging Face Text Generation Inference</a> for LLM serving, <a href="https://www.langchain.com/" target="_blank">Langchain</a> as the "glue" between those components, and <a href="https://www.gradio.app/" target="_blank">Gradio</a> as the UI engine.</p>
<h3 id="requirements">Requirements</h3>
<ul>
<li>An OpenShift cluster with RHODS or ODH deployed.</li>
<li>A node with a GPU card. For the model we will use, 24GB memory on the GPU (VRAM) is necessary. If you have less than that you can either use quantization when loading the model, use an already quantized model (results may vary as they are not all compatible with the model server), or choose another compatible smaller model.</li>
<li>If you don't want to have to manually install different requirements in the notebooks environment (mostly Langchain and its dependencies), which may take time, you may want to directly import this custom workbench image, <a href="http://quay.io/opendatahub-contrib/workbench-images:cuda-jupyter-langchain-c9s-py311_2023c_latest" target="_blank">quay.io/opendatahub-contrib/workbench-images:cuda-jupyter-langchain-c9s-py311_2023c_latest</a>, inside your RHODS/ODH environment. It comes pre-installed with Langchain and many other LLM-related tools. If you don't know how to do this, see the <a href="../../../odh-rhods/configuration/#custom-notebook-images" target="_blank">instructions here</a>.</li>
</ul>
<h3 id="model-serving">Model Serving</h3>
<p>Deploy an HF-TGI instance following the instructions <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/hf_tgis_deployment/README.md" target="_blank">available here</a>.</p>
<p>The model we want to use is Mistral-7B-Instruct as it has been specially fine-tuned for chat interactions. Our deployment must therefore be modified by changing the environment parameters as follows:</p>
<div class="highlight"><pre><span></span><code><span class="w">          </span><span class="nt">env</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MODEL_ID</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mistralai/Mistral-7B-Instruct-v0.1</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MAX_INPUT_LENGTH</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1024&#39;</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MAX_TOTAL_TOKENS</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;2048&#39;</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">HUGGINGFACE_HUB_CACHE</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/models-cache</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PORT</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3000&#39;</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">HOST</span>
<span class="w">              </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0.0.0</span>
</code></pre></div>
<p>What has changed compared to the original deployment is:</p>
<ul>
<li>The MODEL_ID, now <code>mistralai/Mistral-7B-Instruct-v0.1</code></li>
<li>QUANTIZATION has been removed. Again, this depends on your VRAM availability.</li>
</ul>
<p>Once the model is deployed, you can test it as indicated in the instructions on the repo:</p>
<h3 id="vector-store">Vector Store</h3>
<h4 id="redis-deployment">Redis deployment</h4>
<p>For our RAG we will need a Vector Database to store the Embeddings of the different documents. In this example we are using Redis.</p>
<p>Deployment instructions are <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/redis_deployment/README.md" target="_blank">available here</a>.</p>
<p>After you follow those instructions you should have a Database ready to be populated with documents.</p>
<h4 id="document-ingestion">Document ingestion</h4>
<p>In <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/examples/notebooks/langchain/Langchain-Redis-Ingest.ipynb" target="_blank">this notebook</a> you will find detailed instructions on how to ingest different types of documents: PDFs first, then Web pages.</p>
<p>The examples are based on RHODS documentation, but of course we encourage you to use your own documentation. After all that's the purpose of all of this!</p>
<p>This <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/examples/notebooks/langchain/Langchain-Redis-Query.ipynb" target="_blank">other notebook</a> will allow you to execute simple queries against your Vector Store to make sure it works alright.</p>
<h3 id="testing">Testing</h3>
<p>Now let's put all of this together!</p>
<p><a href="https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/examples/notebooks/langchain/RAG_with_sources_Langchain-HFTGI-Redis.ipynb" target="_blank">This notebook</a> requires only information about your Model Server (the Inference URL) and about your Vector store.</p>
<ul>
<li>It will first initialize a connection to the vector database (embeddings are necessary for the Retriever to "understand" what is stored in the database):</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">embeddings</span> <span class="o">=</span> <span class="n">HuggingFaceEmbeddings</span><span class="p">()</span>
<span class="n">rds</span> <span class="o">=</span> <span class="n">Redis</span><span class="o">.</span><span class="n">from_existing_index</span><span class="p">(</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">redis_url</span><span class="o">=</span><span class="n">redis_url</span><span class="p">,</span>
    <span class="n">index_name</span><span class="o">=</span><span class="n">index_name</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema_name</span>
<span class="p">)</span>
</code></pre></div>
<ul>
<li>A prompt template is then defined. You can see that we will give it specific instructions on how the model must answer. This is necessary if you want to keep it focused on its task and not say anything that may not be appropriate (on top of getting you fired!). The format of this prompt is originally the one used for Llama2, but Mistral uses the same one. You may have to adapt this format if you use another model.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">template</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;</span>
<span class="s2">You are a helpful, respectful and honest assistant.</span>
<span class="s2">You will be given a question you need to answer, and a context to provide you with information. You must answer the question based as much as possible on this context.</span>
<span class="s2">Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.</span>

<span class="s2">If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don&#39;t know the answer to a question, please don&#39;t share false information.</span>
<span class="s2">&lt;&lt;/SYS&gt;&gt;</span>

<span class="s2">Question: </span><span class="si">{question}</span>
<span class="s2">Context: </span><span class="si">{context}</span><span class="s2"> [/INST]</span>
<span class="s2">&quot;&quot;&quot;</span>
</code></pre></div>
<ul>
<li>Now we will define the llm connection itself. As you can see there are many parameters you can define that will modify how the model will answer. Details on those parameters are available <a href="https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html" target="_blank">here</a>.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">llm</span> <span class="o">=</span> <span class="n">HuggingFaceTextGenInference</span><span class="p">(</span>
    <span class="n">inference_server_url</span><span class="o">=</span><span class="n">inference_server_url</span><span class="p">,</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">typical_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.175</span><span class="p">,</span>
    <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">StreamingStdOutCallbackHandler</span><span class="p">()]</span>
<span class="p">)</span>
</code></pre></div>
<ul>
<li>And finally we can tie it all together with a specific chain, RetrievalQA:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">qa_chain</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span>
                                       <span class="n">retriever</span><span class="o">=</span><span class="n">rds</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_type</span><span class="o">=</span><span class="s2">&quot;similarity&quot;</span><span class="p">,</span> <span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;distance_threshold&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}),</span>
                                       <span class="n">chain_type_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">QA_CHAIN_PROMPT</span><span class="p">},</span>
                                       <span class="n">return_source_documents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>That's it! We can now use this chain to send queries. The retriever will look for relevant documents in the Vector Store, their content will be injected automatically in the prompt, and the LLM will try to create a valid answer based on its own knowledge and this content:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;How can I work with GPU and taints?&quot;</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">qa_chain</span><span class="p">({</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="n">question</span><span class="p">})</span>
</code></pre></div>
<ul>
<li>The last cell in the notebook will simply filter for duplicates in the sources that were returned in the <code>result</code>, and display them:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">remove_duplicates</span><span class="p">(</span><span class="n">input_list</span><span class="p">):</span>
    <span class="n">unique_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">input_list</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_list</span><span class="p">:</span>
            <span class="n">unique_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s1">&#39;source&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">unique_list</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">remove_duplicates</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;source_documents&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div>
<h3 id="application">Application</h3>
<p>Notebooks are great and everything, but it's not what you want to show to your users. I hope...</p>
<p>So <a href="https://github.com/rh-aiservices-bu/llm-on-openshift/tree/main/examples/ui/gradio/gradio-hftgi-rag-redis">here is a simple UI</a> you can put around the same code we used in the notebooks.</p>
<p>The deployment is already explained in the repo and pretty straightforward as the application will only "consume" the same Vector Store and LLM Serving we have used in the notebooks. However I will point out some specificities:</p>
<ul>
<li>As you should have noticed on the document ingestion part, a schema has been created for your index when you imported the first documents. This schema must be included in a ConfigMap that will be mounted in the Pod at runtime. This allows for a more generic Pod image that will work with any schema you will define (there are many things you can do here, like adding metadata, but that's a story for another time...).</li>
<li>Don't forget to put your Inference Server and Redis information in the environment variables of the Deployment! This one is scaled down to zero initially to give you time to do it properly, so don't forget to scale it up before opening an issue because the deployment does not start...</li>
</ul>
<p>Some info on the code itself (<code>app.py</code>):</p>
<ul>
<li><code>load_dotenv</code>, along with the <code>env.example</code> file (once renamed <code>.env</code>) will allow you to develop locally.</li>
<li>As normally your Redis server won't be exposed externally to OpenShift, if you want to develop locally you may want to open a tunnel to it with <code>oc port-forward pod-name 14155:14155</code> (replace with the name of the Redis Pod where the Service is connected and the ports used). You can use the same technique for the LLM endpoint if you have not exposed it as a route.</li>
<li>The class <code>QueueCallback</code> was necessary because the <code>HuggingFaceTextGenInference</code> library used to query the model does not return an iterator in the format Langchain expects it (at the time of this writing). So instead this implementation of the Callback functions for the LLM puts the new tokens in a Queue (L43) that is then retrieved from continuously (L78), with the content being yielded for display. This is a little bit convoluted, but the whole stack is still in full development, so sometimes you have to be creative...</li>
<li>Gradio configuration is pretty straightforward trough the ChatInterface component, only hiding some buttons, adding an avatar image for the bot,...</li>
</ul>
<p>Here is what you RAG-based Chatbot should look like (some tweaking on the App title that you can do through the environment variable):</p>
<video controls autoplay loop muted>
      <source id="mp4" src="/demos/llm-chat-doc/img/chatbot-demo.mp4" type="video/mp4">
      <img src="/demos/llm-chat-doc/img/chatbot-ui.png" title="Your browser does not support the <video> tag" />
</videos>


  




                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
<footer class="md-footer">
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                
                powered by
                <a href="https://www.mkdocs.org" title="MkDocs" target="_blank">MkDocs</a>
                and
                <a href="https://squidfunk.github.io/mkdocs-material/"
                   title="Material for MkDocs" target="_blank">
                    Material for MkDocs</a>
            </div>
            
            <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://discord.gg/q2Y6THPQKb" target="_blank" rel="noopener" title="discord.gg" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485.065 485.065 0 0 0 404.081 32.03a1.816 1.816 0 0 0-1.923.91 337.461 337.461 0 0 0-14.9 30.6 447.848 447.848 0 0 0-134.426 0 309.541 309.541 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.689 483.689 0 0 0-119.688 37.107 1.712 1.712 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.016 2.016 0 0 0 .765 1.375 487.666 487.666 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348.2 348.2 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321.173 321.173 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251.047 251.047 0 0 0 9.109-7.137 1.819 1.819 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.812 1.812 0 0 1 1.924.233 234.533 234.533 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.407 301.407 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391.055 391.055 0 0 0 30.014 48.815 1.864 1.864 0 0 0 2.063.7A486.048 486.048 0 0 0 610.7 405.729a1.882 1.882 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541ZM222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241Zm195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241Z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.reddit.com/r/AI_on_OpenShift/" target="_blank" rel="noopener" title="www.reddit.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://odh-io.slack.com/" target="_blank" rel="noopener" title="odh-io.slack.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>
    </a>
  
</div>
            
        </div>
    </div>
</footer>

    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            

  
    
  


  
    
  



  


<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="analytics" checked>
          <span class="task-list-indicator"></span>
          Google Analytics
        </label>
      </li>
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        </label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.copy", "navigation.instant", "navigation.tracking", "navigation.sections", "navigation.indexes", "navigation.top", "navigation.tabs"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.aecac24b.min.js"></script>
      
    
  </body>
</html>